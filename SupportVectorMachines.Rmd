---
title: "Max_SVM_assignment2"
author: "Max Mo Jynge"
date: "2023-04-15"
output: html_document
---

# Assignment 2: Support Vector Machines (SVM)

In order to understand how the **support vector machine** works, we must first understand how the simpler **support vector classifier** works - because the support vector machine relies on the support vector classifier in order for it to form its decision boundary. Lets look at a simple example using a support vector classifier:

## Support vector classifiers:

```{r}
rm(list = ls())
library(ggplot2)
library(GGally)
library(e1071)
library(Hmisc)

heart = read.csv("heart.csv")
heart[, sapply(heart, is.character)] <- lapply(heart[, sapply(heart, is.character)], factor)
heart$HeartDisease = as.factor(heart$HeartDisease)

for (col in names(heart)) {
  if (is.character(heart[col])) {
    heart[col] <- as.factor(heart[col])
  }
}
heart$FastingBS = as.factor(heart$FastingBS)

heart$Cholesterol[heart$Cholesterol == 0] = NA
heart$Cholesterol = impute(heart$Cholesterol, median)


dim(heart)
names(heart)
#View(heart)
str(heart)
```

Let's first look at an example with a single covariate and a single response, namely HeartDisease against Age.

```{r}
set.seed(25)
train = sample(nrow(heart), nrow(heart)*0.8); test = -train
heart.train = heart[train, ]
heart.test  = heart[test, ]
```

```{r}
plot(heart.train$Age, heart.train$Cholesterol, col=heart.train$HeartDisease)
```

```{r}
tune.out = tune(svm, HeartDisease ~ ., data = heart.train, 
                kernel = "radial", 
                ranges = list(cost = c(0.1, 1, 10), gamma = c(0.5, 1, 2)
              ))
summary(tune.out)
```

```{r}
svmfit = function(formula_svm, formula_plot, data.train, data.test, kernel, cost, gamma) {
  svmfit = svm(formula = formula_svm, 
             data = data.train, 
             kernel = kernel,
             gamma = gamma,
             cost = cost,
             scale=TRUE)
  plot(svmfit, heart.train, formula_plot)
  
  heart.pred = predict(svmfit, heart.test)
  table_data = table(predict = heart.pred, truth = data.test$HeartDisease)
  print(table_data)
  
  sensitivity = table_data[1] / (table_data[1] + table_data[2])
  sens = sprintf("Sensitivity: %.2f", sensitivity); print(sens)
  specificity = table_data[4] / (table_data[4] + table_data[3])
  spec = sprintf("Specificity: %.2f", specificity); print(spec)
}

svmfit(HeartDisease ~ ., MaxHR ~ , heart.train, heart.test, "radial", 1, 0.5)
```

Qualitatively the results for both radial and linear kernel seem similar. Hence, we need a quantitative approach in order to determine which kernel works the best.

## Support vector classifiers:

```{r}
set.seed(1)
x = matrix(rnorm(20 * 2), ncol = 2)
y = c(rep(-1, 10), rep(1, 10))
x[y==1, ] = x[y==1, ] +1
plot(x, col= (3-y))
```

```{r}
library(e1071)
dat = data.frame(x=x, y = as.factor(y))
svmfit = svm(y ~ ., data = dat, kernel="linear", cost=10, scale=FALSE)
plot(svmfit, dat)
```

Support vectors are plotted as crosses. The remaining points as circles. We can find what vectors are support vectors using \$index.

```{r}
svmfit$index
length(svmfit$index)
```

```{r}
summary(svmfit)
```

```{r}
svmfit = svm(y ~ ., data = dat, kernel="linear", cost=0.1, scale=FALSE)
plot(svmfit, dat)
```

```{r}
svmfit$index
length(svmfit$index)
```

```{r}
set.seed(1)

tune.out = tune(svm, y ~ ., data=dat, kernel="linear", 
                ranges = list(cost=c(0.001, 0.01, 0.1, 1, 5, 10, 100)))

summary(tune.out)

```

```{r}
bestmod = tune.out$best.model # Get the model with the best cost-value. 
summary(bestmod)
```

```{r}
xtest = matrix(rnorm(20*2), ncol=2)
ytest = sample(c(-1, 1), 20, replace =TRUE)
xtest[ytest == 1, ] = xtest[ytest == 1, ] + 1
testdat = data.frame(x=xtest, y=as.factor(ytest))


ypred = predict(bestmod, testdat)
table(predict = ypred, truth = testdat$y)
```

Thus, for cost= 0.1 (which is the best model) yields a classification rate of 17 correct and 3 wrong. What if we instead used cost = 0.01?

```{r}
# trained model using training data. 
svmfit = svm(y ~ ., data = dat, kernel="linear", cost = 0.01, scale=FALSE) 

# predictions: 
ypred = predict(svmfit, testdat)

table(predict = ypred, truth = testdat$y)
```

Now we see that two more observations are classified.

```{r}
x[y==1, ] = x[y==1, ] + 0.5
plot(x, col= (y+5)/2, pch = 19)
```

```{r}
dat = data.frame(x=x, y = as.factor(y))
svmfit_large = svm(y ~ ., data = dat, kernel="linear", cost=1e10)
svmfit_small = svm(y ~ ., data = dat, kernel="linear", cost=1)
summary(svmfit_large)
```

```{r}
plot(svmfit_large, dat)
plot(svmfit_small, dat)
```

```{r}
svmfit_large$index
svmfit_small$index
```

So, in summary, the cost parameter controls the trade-off between maximizing the **margin** and minimizing the **classification error**.

-   Large cost =\> Lower misclassification rate , but smaller margin.

-   Low cost =\> Higher misclassification rate, but greater margin.

## Support vector machines:

```{r}
set.seed(1)
x = matrix(rnorm(200*2), ncol=2)
x[1:100, ] = x[1:100, ] + 2
x[101:150, ] = x[101:150,] - 2
y = c(rep(1, 150), rep(2, 50))
dat = data.frame(x = x, y = as.factor(y))

plot(x, col=y)
```

Notice that we only use svm() with the data = dat[train, ]. This is because we only fit our model with training data, and then later test the model and fit with the remaining test-data.

```{r}
train = sample(200, 100) # 100 data points (second argument) are training points. 
svmfit = svm(y ~ ., data = dat[train, ], kernel="radial", gamma = 1, cost = 1)
plot(svmfit, dat[train, ])
```

```{r}
summary(svmfit)
```

Now, let's try a fit with higher cost (so that we can have a lower training misclassification).

```{r}
svmfit = svm(y ~ ., data = dat[train, ], kernel = "radial", gamma = 1, cost = 1e5)
plot(svmfit, dat[train, ])
```

As with the radial kernel, we see that for a higher cost, the misclassification rate is lowered. As a consequence, the margin is smaller.

But what is the best cost?? Let's do cross validation!

```{r}
set.seed(1)
tune.out = tune(svm, y ~ ., data = dat[train, ],
                kernel = "radial", 
                ranges = list(cost = c(0.1, 1, 10, 100, 1000), 
                              gamma = c(0.5, 1, 2, 3, 4)
                      )
                )

summary(tune.out)
```

```{r}
table(
  true = dat[-train, "y"],
  pred = predict(tune.out$best.model, newdata = dat[-train, ])
)

```

## ROC Curves:

```{r}
library(ROCR)
rocplot = function(pred, truth, ...) {
  predob = prediction(pred, truth)
  perf = performance(predob, "tpr", "fpr")
  plot(perf, ...)
}

svmfit.opt = svm(y ~ ., data = dat[train, ], 
                 kernel = "radial", 
                 gamma = 2, 
                 cost = 1, 
                 decision.values = TRUE)

fitted = attributes(
  predict(svmfit.opt, dat[train, ], decision.values = TRUE)
)$decision.values
```

```{r}
rocplot(-fitted, dat[train, "y"], main = "Training Data")


svmfit.flex = svm(y ~ ., data = dat[train, ], 
                  kernel = "radial", 
                  gamma = 50, 
                  cost = 1, 
                  decision.values = TRUE)
fitted = attributes(
  predict(svmfit.flex, dat[train, ], decision.values = TRUE)
)$decision.values
rocplot(-fitted, dat[train, "y"], add = TRUE, col="red")
```

```{r}
fitted = attributes(
  predict(svmfit.opt, dat[-train, ], decision.values = TRUE)
)$decision.values
rocplot(-fitted, dat[-train, "y"], main = "Test Data")
fitted = attributes(
  predict(svmfit.flex, dat[-train, ], decision.values = TRUE)
)$decision.values
rocplot(-fitted, dat[-train, "y"], add = TRUE, col = "red")
```

## SVM with multiple classes:

```{r}
set.seed(1)
x = rbind(x, matrix(rnorm(50*2), ncol=2))
y = c(y, rep(0, 50))
x[y == 0, 2] = x[y == 0, 2] + 2
dat = data.frame(x = x, y = as.factor(y))
par(mfrow = c(1, 1))
plot(x, col = (y+1))
```

```{r}
svmfit = svm(y ~ ., data = dat, kernel = "radial", cost = 10, gamma = 1)
plot(svmfit, dat)
```
